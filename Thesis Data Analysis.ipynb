{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thesis data generation and analysis\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports, variables and plotting setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import string\n",
    "import random\n",
    "\n",
    "import seaborn as sns; sns.set(color_codes=True)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# import configuration variable with path\n",
    "# to the Golang code of the experiment\n",
    "from config import EXPERIMENT_PATH\n",
    "\n",
    "# build Golang program\n",
    "os.system(\"go build -o \" + EXPERIMENT_PATH + \"/thesis \" + EXPERIMENT_PATH + \"/*.go\")\n",
    "\n",
    "\n",
    "# plotting config\n",
    "plt.style.use('seaborn-talk')\n",
    "sns.set_style(\"white\")\n",
    "sns.set_context(\"paper\", font_scale=1.5)\n",
    "\n",
    "np.random.seed(2424)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run experiment with given params\n",
    "def runExperiment(name, algo=\"mt\", i=10, op=\"build\"):\n",
    "    os.system(EXPERIMENT_PATH + \"/thesis \" + \"-algo=\" + algo +  \" -op=\" + op + \" -name=\" + name + \" -iter=\" + str(i))\n",
    "    \n",
    "# clean source and results folders\n",
    "def cleanupSource():\n",
    "    os.system(\"rm \" + EXPERIMENT_PATH + \"/source/*.txt\")\n",
    "\n",
    "def cleanupResults():\n",
    "    os.system(\"rm \" + EXPERIMENT_PATH + \"/results/*.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate n transactions of uniformly distributed length\n",
    "def genTransactions(lengths, name, sort=False):\n",
    "    \n",
    "    # the function gen_string is vectorized, ready to \n",
    "    # process arrays \n",
    "    vfunc = np.vectorize(random_string)\n",
    "    \n",
    "    # generates strings of given lengths\n",
    "    samples = vfunc(lengths.astype(int))\n",
    "    \n",
    "    if sort:\n",
    "        samples.sort()\n",
    "    \n",
    "    with open(EXPERIMENT_PATH + '/source/' + name, 'w') as output:\n",
    "        for sample in samples:\n",
    "            output.write(sample + '\\n')\n",
    "\n",
    "# generate random string of specified length\n",
    "def random_string(length):\n",
    "    return ''.join(random.choice(string.ascii_letters) for m in range(length)).upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeStats(trials):\n",
    "    # compute means and standard deviations\n",
    "    means = np.mean(trials[1:,:], axis=1)\n",
    "    stds = np.std(trials[1:,:], axis=1)\n",
    "    \n",
    "    return means, stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotDistribution(data, title):\n",
    "    plt.hist(data, bins=200, normed=True)\n",
    "    plt.title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Negative Exponential with λ= 1#  Negati \n",
    "# In probability theory and statistics, the exponential distribution\n",
    "# (also known as negative exponential distribution) is the probability \n",
    "# distribution that describes the time between events in a Poisson \n",
    "# point process, i.e. a process in which events occur continuously \n",
    "# and independently at a constant average rate\n",
    "\n",
    "#  Beta is the scale parameter, which is the inverse of the rate parameter \\lambda = 1/\\beta.\n",
    "\n",
    "BETA = 500\n",
    "\n",
    "def genRandExp(n_samples):\n",
    "    exponential_samples = np.rint(np.random.exponential(BETA, n_samples))\n",
    "    # plotDistribution(exponential_samples, 'Exponential')\n",
    "    # print(exponential_samples)\n",
    "    return exponential_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uniform samples in (0,2) range\n",
    "\n",
    "def genRandUni(n_samples):\n",
    "    uniform_samples = np.rint(np.random.uniform(900, 1100, n_samples))\n",
    "    # plotDistribution(uniform_samples, 'Uniform')\n",
    "    # print(uniform_samples)\n",
    "    return uniform_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This distribution corresponds to the one presented in the papers# This di \n",
    "# I.e. 0.5 (rand)^0.5 is the same as a triangular distribution with left = 0, right = 0.5, mode = 0.5\n",
    "\n",
    "def genRandTri(n_samples):\n",
    "    triang = np.rint(np.random.triangular(left=0, mode=1100, right=1100, size=n_samples))\n",
    "    # plotDistribution(triang, 'Triangular')\n",
    "    # print(triang)\n",
    "    return triang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genExpTransactions(n, name, sort):\n",
    "    lenghts = genRandExp(n)\n",
    "    genTransactions(lenghts, name, sort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genUniTransactions(n, name, sort):\n",
    "    lenghts = genRandUni(n)\n",
    "    genTransactions(lenghts, name, sort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genTriTransactions(n, name, sort):\n",
    "    lenghts = genRandTri(n)\n",
    "    genTransactions(lenghts, name, sort)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Experiment\n",
    "\n",
    "### Uniformly random distributed transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genUniformData(rnge):\n",
    "    for i in range(rnge[0], rnge[1], rnge[2]):\n",
    "        SAMPLE = str(i) + '_uniform_samples.txt'\n",
    "\n",
    "        # generate data (no sorting)\n",
    "        genTriTransactions(i, SAMPLE, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randUniformExperiment(algo, trials, rnge):\n",
    "    for i in range(rnge[0], rnge[1], rnge[2]):\n",
    "        SAMPLE = str(i) + '_uniform_samples.txt'\n",
    "\n",
    "        # run exeperiment\n",
    "        runExperiment(SAMPLE, i=trials, algo=algo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getResults(algo, trials, rnge):\n",
    "    RES_PATH = '/results/result_' + algo + '_'\n",
    "    NUM_TRIALS = trials\n",
    "\n",
    "    build_t = np.arange(NUM_TRIALS)\n",
    "    build_m = np.arange(NUM_TRIALS)\n",
    "    veri_t = np.arange(NUM_TRIALS)\n",
    "    veri_m = np.arange(NUM_TRIALS)\n",
    "\n",
    "    for i in range(rnge[0], rnge[1], rnge[2]):\n",
    "        SAMPLE = str(i) + '_uniform_samples.txt'\n",
    "\n",
    "        # load data in-memory for analysis\n",
    "        result = np.loadtxt(EXPERIMENT_PATH + RES_PATH + SAMPLE, dtype='int', delimiter=', ')\n",
    "        build_t = np.vstack([build_t, result[:,0]])\n",
    "        build_m = np.vstack([build_m, result[:,1]])\n",
    "        veri_t = np.vstack([veri_t, result[:,2]])\n",
    "        veri_m = np.vstack([veri_m, result[:,3]])\n",
    "    \n",
    "\n",
    "    return build_t, build_m, veri_t, veri_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "/Users/daynex/Code/Go/src/github.com/SimoneStefani/thesis-algorithms/results/result_sl_100_uniform_samples.txt not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-205bc3738f36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mrandUniformExperiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTRIALS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRANGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0msl_build_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msl_build_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msl_veri_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msl_veri_m\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetResults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTRIALS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRANGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0msl_build_t_means\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msl_build_t_stds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomputeStats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msl_build_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0msl_build_m_means\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msl_build_m_stds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomputeStats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msl_build_m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-b8f54492a409>\u001b[0m in \u001b[0;36mgetResults\u001b[0;34m(algo, trials, rnge)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# load data in-memory for analysis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEXPERIMENT_PATH\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mRES_PATH\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mSAMPLE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'int'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m', '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mbuild_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbuild_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mbuild_m\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbuild_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/py36/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding)\u001b[0m\n\u001b[1;32m    915\u001b[0m             \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_string_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_datasource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m             \u001b[0mfencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'encoding'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/py36/lib/python3.6/site-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataSource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnewline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/py36/lib/python3.6/site-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[1;32m    614\u001b[0m                                       encoding=encoding, newline=newline)\n\u001b[1;32m    615\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 616\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s not found.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    617\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: /Users/daynex/Code/Go/src/github.com/SimoneStefani/thesis-algorithms/results/result_sl_100_uniform_samples.txt not found."
     ]
    }
   ],
   "source": [
    "RANGE = 100, 700, 50\n",
    "TRIALS = 30\n",
    "\n",
    "\n",
    "# -- START EXPERIMENT -- #\n",
    "\n",
    "cleanupResults()\n",
    "cleanupSource()\n",
    "genUniformData(RANGE)\n",
    "\n",
    "randUniformExperiment('hl', TRIALS, RANGE)\n",
    "hl_build_t, hl_build_m, hl_veri_t, hl_veri_m = getResults('hl', TRIALS, RANGE)\n",
    "hl_build_t_means, hl_build_t_stds = computeStats(hl_build_t)\n",
    "hl_build_m_means, hl_build_m_stds = computeStats(hl_build_m)\n",
    "hl_veri_t_means, hl_veri_t_stds = computeStats(hl_veri_t)\n",
    "hl_veri_m_means, hl_veri_m_stds = computeStats(hl_veri_m)\n",
    "\n",
    "\n",
    "randUniformExperiment('mt', TRIALS, RANGE)\n",
    "mt_build_t, mt_build_m, mt_veri_t, mt_veri_m = getResults('mt', TRIALS, RANGE)\n",
    "mt_build_t_means, mt_build_t_stds = computeStats(mt_build_t)\n",
    "mt_build_m_means, mt_build_m_stds = computeStats(mt_build_m)\n",
    "mt_veri_t_means, mt_veri_t_stds = computeStats(mt_veri_t)\n",
    "mt_veri_m_means, mt_veri_m_stds = computeStats(mt_veri_m)\n",
    "\n",
    "randUniformExperiment('fmt', TRIALS, RANGE)\n",
    "fmt_build_t, fmt_build_m, fmt_veri_t, fmt_veri_m = getResults('fmt', TRIALS, RANGE)\n",
    "fmt_build_t_means, fmt_build_t_stds = computeStats(fmt_build_t)\n",
    "fmt_build_m_means, fmt_build_m_stds = computeStats(fmt_build_m)\n",
    "fmt_veri_t_means, fmt_veri_t_stds = computeStats(fmt_veri_t)\n",
    "fmt_veri_m_means, fmt_veri_m_stds = computeStats(fmt_veri_m)\n",
    "\n",
    "randUniformExperiment('sl', TRIALS, RANGE)\n",
    "sl_build_t, sl_build_m, sl_veri_t, sl_veri_m = getResults('sl', TRIALS, RANGE)\n",
    "sl_build_t_means, sl_build_t_stds = computeStats(sl_build_t)\n",
    "sl_build_m_means, sl_build_m_stds = computeStats(sl_build_m)\n",
    "sl_veri_t_means, sl_veri_t_stds = computeStats(sl_veri_t)\n",
    "sl_veri_m_means, sl_veri_m_stds = computeStats(sl_veri_m)\n",
    "\n",
    "lenghts = np.arange(RANGE[0], RANGE[1], RANGE[2])\n",
    "\n",
    "# -- END EXPERIMENT -- #\n",
    "\n",
    "\n",
    "# build plot\n",
    "plt.errorbar(lenghts, hl_build_t_means, yerr=hl_build_t_stds, marker='o', color='orange', label='Hashlist')\n",
    "plt.errorbar(lenghts, mt_build_t_means, yerr=mt_build_t_stds, marker='o', label='Merkle Tree')\n",
    "plt.errorbar(lenghts, fmt_build_t_means, yerr=fmt_build_t_stds, marker='o', color='red', label='Fast Merkle Tree')\n",
    "plt.errorbar(lenghts, sl_build_t_means, yerr=sl_build_t_stds, marker='o', color='green', label='Authenticated Append-Only Skip List')\n",
    "plt.title('Execution time for data structures of different lengths')\n",
    "plt.grid(True)\n",
    "plt.xlabel('Number of Transactions')\n",
    "plt.ylabel('Execution Time (µs)')\n",
    "plt.legend(bbox_to_anchor=(0, 1), loc=2, borderaxespad=0.)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build plot\n",
    "plt.errorbar(lenghts, hl_build_m_means, yerr=hl_build_m_stds, marker='o', color='orange', label='Hashlist')\n",
    "plt.errorbar(lenghts, mt_build_m_means, yerr=mt_build_m_stds, marker='o', label='Merkle Tree')\n",
    "plt.errorbar(lenghts, fmt_build_m_means, yerr=fmt_build_m_stds, marker='o', color='red', label='Fast Merkle Tree')\n",
    "#plt.errorbar(lenghts, sl_build_m_means, yerr=sl_build_m_stds, marker='o', color='green', label='Authenticated Append-Only Skip List')\n",
    "plt.title('Execution time for data structures of different lengths')\n",
    "plt.grid(True)\n",
    "plt.xlabel('Number of Transactions')\n",
    "plt.ylabel('Execution Time (µs)')\n",
    "plt.legend(bbox_to_anchor=(0, 1), loc=2, borderaxespad=0.)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build plot\n",
    "plt.errorbar(lenghts, hl_veri_t_means, yerr=hl_veri_t_stds, marker='o', color='orange', label='Hashlist')\n",
    "plt.errorbar(lenghts, mt_veri_t_means, yerr=mt_veri_t_stds, marker='o', label='Merkle Tree')\n",
    "plt.errorbar(lenghts, fmt_veri_t_means, yerr=fmt_build_t_stds, marker='o', color='red', label='Fast Merkle Tree')\n",
    "#plt.errorbar(lenghts, sl_veri_t_means, yerr=sl_veri_t_stds, marker='o', color='green', label='Authenticated Append-Only Skip List')\n",
    "plt.title('Execution time for the verifiication process for data structures of different lengths')\n",
    "plt.grid(True)\n",
    "plt.xlabel('Number of Transactions')\n",
    "plt.ylabel('Execution Time (µs)')\n",
    "plt.legend(bbox_to_anchor=(0, 1), loc=2, borderaxespad=0.)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build plot\n",
    "plt.errorbar(lenghts, hl_veri_m_means, yerr=hl_veri_m_stds, marker='o', color='orange', label='Hashlist')\n",
    "plt.errorbar(lenghts, mt_veri_m_means, yerr=mt_veri_m_stds, marker='o', label='Merkle Tree')\n",
    "plt.errorbar(lenghts, fmt_veri_m_means, yerr=fmt_build_m_stds, marker='o', color='red', label='Fast Merkle Tree')\n",
    "plt.title('Memory Allocation for the verifiication process for data structures of different lengths')\n",
    "plt.grid(True)\n",
    "plt.xlabel('Number of Transactions')\n",
    "plt.ylabel('Execution Time (µs)')\n",
    "plt.legend(bbox_to_anchor=(0, 1), loc=2, borderaxespad=0.)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
